{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"[homework]knn.ipynb\"","provenance":[{"file_id":"1-mw8yb1rdfUZYTCvH92jhWu5UoHYkEnP","timestamp":1633536499864}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pgFYFftQKxY5"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:450px;\" width=500/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n","<h3 style=\"text-align: center;\"><b>Базовый и продвинутый потоки. Осень 2021</b></h3>\n","\n","<h1 style=\"text-align: center;\"><b>Домашнее задание. Библиотека sklearn и классификация с помощью KNN</b></h1>"]},{"cell_type":"markdown","metadata":{"id":"v4RCHGZULaWz"},"source":["На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."]},{"cell_type":"markdown","metadata":{"id":"F2acNQu1L94J"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Twe_cnn5KxY6"},"source":["<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"YD0NXyUYKxY7"},"source":["Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "]},{"cell_type":"markdown","metadata":{"id":"CTa2jNZkKxY8"},"source":["<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"]},{"cell_type":"markdown","metadata":{"id":"5H7wPU0IKxY-"},"source":["\n","Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n","\n","* Вычислить расстояние до каждого из объектов обучающей выборки\n","* Отобрать объектов обучающей выборки, расстояние до которых минимально\n","* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"]},{"cell_type":"markdown","metadata":{"id":"T2docs4225pb"},"source":["Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке."]},{"cell_type":"markdown","metadata":{"id":"AcjJQX3wKxZA"},"source":["### Обработка данных"]},{"cell_type":"code","metadata":{"id":"Ozcx5mVOKxZB"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ry4bMKaUjHJj"},"source":["Сcылка на датасет (лежит в папке): https://drive.google.com/drive/folders/16TSz1P-oTF8iXSQ1xrt0r_VO35xKmUes?usp=sharing"]},{"cell_type":"code","metadata":{"id":"rvPrVRvK25pc","colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"status":"ok","timestamp":1633646282454,"user_tz":-180,"elapsed":268,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"286340b4-16ea-43d8-996c-055105fb7fbc"},"source":["all_data = pd.read_csv('forest_dataset.csv')\n","all_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2683</td>\n","      <td>333</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>2743</td>\n","      <td>121</td>\n","      <td>173</td>\n","      <td>179</td>\n","      <td>6572</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2915</td>\n","      <td>90</td>\n","      <td>8</td>\n","      <td>216</td>\n","      <td>11</td>\n","      <td>4433</td>\n","      <td>232</td>\n","      <td>228</td>\n","      <td>129</td>\n","      <td>4019</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2941</td>\n","      <td>162</td>\n","      <td>7</td>\n","      <td>698</td>\n","      <td>76</td>\n","      <td>2783</td>\n","      <td>227</td>\n","      <td>242</td>\n","      <td>148</td>\n","      <td>1784</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3096</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>170</td>\n","      <td>3</td>\n","      <td>3303</td>\n","      <td>231</td>\n","      <td>202</td>\n","      <td>99</td>\n","      <td>5370</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2999</td>\n","      <td>66</td>\n","      <td>8</td>\n","      <td>488</td>\n","      <td>37</td>\n","      <td>1532</td>\n","      <td>228</td>\n","      <td>225</td>\n","      <td>131</td>\n","      <td>2290</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0    1   2    3   4     5    6    7  ...  47  48  49  50  51  52  53  54\n","0  2683  333  35   30  26  2743  121  173  ...   0   0   0   0   0   0   0   2\n","1  2915   90   8  216  11  4433  232  228  ...   0   0   0   0   0   0   0   1\n","2  2941  162   7  698  76  2783  227  242  ...   0   0   0   0   0   0   0   2\n","3  3096   60  17  170   3  3303  231  202  ...   0   0   0   0   0   0   0   1\n","4  2999   66   8  488  37  1532  228  225  ...   0   0   0   0   0   0   0   2\n","\n","[5 rows x 55 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"_o8yXBPSKxZI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633645150931,"user_tz":-180,"elapsed":12,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"494e7c01-265d-4e7f-9c04-be2aafe17876"},"source":["all_data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 55)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"itCWxHEY25pg"},"source":["Выделим значения метки класса в переменную `labels`, признаковые описания --- в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."]},{"cell_type":"code","metadata":{"id":"f_YIUOuV25ph","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633646286610,"user_tz":-180,"elapsed":371,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"463e8dec-3a96-4857-933b-476f5a7f78b0"},"source":["labels = all_data[all_data.columns[-1]].values\n","feature_matrix = all_data[all_data.columns[:-1]].values\n","labels, feature_matrix"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([2, 1, 2, ..., 2, 2, 2]),\n"," array([[2683,  333,   35, ...,    0,    0,    0],\n","        [2915,   90,    8, ...,    0,    0,    0],\n","        [2941,  162,    7, ...,    0,    0,    0],\n","        ...,\n","        [2693,   21,   11, ...,    0,    0,    0],\n","        [2536,   42,   11, ...,    0,    0,    0],\n","        [3109,  261,   10, ...,    0,    0,    0]]))"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"FukXaH_r8PMQ"},"source":["### Пара слов о sklearn"]},{"cell_type":"markdown","metadata":{"id":"k5S_0Lfc8PMR"},"source":["**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."]},{"cell_type":"markdown","metadata":{"id":"VhVDEG538PMS"},"source":["`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."]},{"cell_type":"markdown","metadata":{"id":"QJZQulsp8PMT"},"source":["Познакомимся со вспомогательной функцией \n","[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","С её помощью можно разбить выборку на обучающую и тестовую части."]},{"cell_type":"code","metadata":{"id":"Q030jzyY25pl"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkeB47mX8PMY"},"source":["Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."]},{"cell_type":"code","metadata":{"id":"YJN0jFARKxZX"},"source":["train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n","    feature_matrix, labels, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"odC1c7X48PMb"},"source":["Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."]},{"cell_type":"markdown","metadata":{"id":"z3fGvPqG8PMc"},"source":["Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n","\n","В качестве примера модели можно привести классификаторы\n","[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n","[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."]},{"cell_type":"markdown","metadata":{"id":"IuX8Rc7c8PMd"},"source":["У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."]},{"cell_type":"markdown","metadata":{"id":"ZYokUkxO8PMe"},"source":["Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n","\n","У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n","\n","Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n","\n","Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n","\n","Рассмотрим всё это на примере логистической регрессии."]},{"cell_type":"code","metadata":{"id":"ew0Ji_2D8PMe"},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9KcMHXr8PMh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633647377388,"user_tz":-180,"elapsed":1489,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"06f0e640-26c1-4122-f65a-ca04a49f4b7a"},"source":["# создание модели с указанием гиперпараметра C\n","clf = LogisticRegression(C=1)\n","# обучение модели\n","clf.fit(train_feature_matrix, train_labels)\n","# предсказание на тестовой выборке\n","y_pred = clf.predict(test_feature_matrix)\n","y_pred"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 2, ..., 1, 2, 1])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"h3gjg3pm8PMm"},"source":["Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."]},{"cell_type":"code","metadata":{"id":"J2Ej1Lni8PMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633647380287,"user_tz":-180,"elapsed":277,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"b99cf9b2-8104-4b4d-ed3f-d5b16fa746fd"},"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_labels, y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6075"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"malIDW_P8PMp"},"source":["Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n","\n","Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n","\n","У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."]},{"cell_type":"code","metadata":{"id":"vq687Aoc8PMq"},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVnqHBvK8PMs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633647544043,"user_tz":-180,"elapsed":99711,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"465716c4-78e9-416b-e827-80b9d84d81a0"},"source":["# заново создадим модель, указав солвер\n","clf = LogisticRegression(solver='saga')\n","\n","# опишем сетку, по которой будем искать\n","param_grid = {\n","    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\n","    'penalty': ['l1', 'l2'],\n","}\n","\n","# создадим объект GridSearchCV\n","search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n","\n","# запустим поиск\n","search.fit(feature_matrix, labels)\n","\n","# выведем наилучшие параметры\n","print(search.best_params_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'C': 1, 'penalty': 'l1'}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"]}]},{"cell_type":"markdown","metadata":{"id":"DnVTFcvZ8PMv"},"source":["В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."]},{"cell_type":"code","metadata":{"id":"ArKINrE_8PMw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633649211613,"user_tz":-180,"elapsed":218,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"096d09f1-2d9c-45a8-c11f-cac62c99037b"},"source":["accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6418"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"okzpKY_I8PMz"},"source":["Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."]},{"cell_type":"markdown","metadata":{"id":"_mdJyxdo8PM1"},"source":["В заданиях вам предстоит повторить это для метода ближайших соседей."]},{"cell_type":"markdown","metadata":{"id":"z8W__017KxZc"},"source":["### Обучение модели"]},{"cell_type":"markdown","metadata":{"id":"02uT6CPYKxZe"},"source":["Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n","\n","* число соседей `n_neighbors`\n","* метрика расстояния между объектами `metric`\n","* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"]},{"cell_type":"markdown","metadata":{"id":"BHVNCaJ325qD"},"source":["Обучите на датасете `KNeighborsClassifier` из `sklearn`."]},{"cell_type":"code","metadata":{"id":"o4CMnnOY25qD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633647637814,"user_tz":-180,"elapsed":596,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"238ff44a-6968-4b23-a3cc-27d4f78db213"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","clf = KNeighborsClassifier()\n","\n","clf.fit(train_feature_matrix, train_labels)\n","# предсказание на тестовой выборке\n","y_pred = clf.predict(test_feature_matrix)\n","y_pred\n","# Ваш код здесь"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 2, ..., 1, 2, 1])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz_ydrHk_L3E","executionInfo":{"status":"ok","timestamp":1633647644611,"user_tz":-180,"elapsed":241,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"aed6f47f-f492-40fa-e354-e8ae3396c9a0"},"source":["accuracy_score(test_labels, y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7365"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"r_2Mf8BiKxZk"},"source":["### Вопрос 1:\n","* Какое качество у вас получилось?"]},{"cell_type":"markdown","metadata":{"id":"uFTIaPdrKxZl"},"source":["Подберём параметры нашей модели"]},{"cell_type":"markdown","metadata":{"id":"8WzoRJZd25qF"},"source":["* Переберите по сетке от `1` до `10` параметр числа соседей\n","\n","* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n","\n","* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"]},{"cell_type":"code","metadata":{"id":"4lMSy-6f25qG","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633648593388,"user_tz":-180,"elapsed":21745,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"9a620122-936d-42ae-bf2f-bde140ae702e"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","clf = KNeighborsClassifier()\n","\n","params = {\n","    'n_neighbors': np.arange(1, 11), \n","    'metric': ('manhattan', 'euclidian'), \n","    'weights': ('uniform', 'distance')\n","    }\n","\n","clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n","# Теперь обучение. Ваш код здесь\n","clf_grid.fit(feature_matrix, labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n","                                            metric='minkowski',\n","                                            metric_params=None, n_jobs=None,\n","                                            n_neighbors=5, p=2,\n","                                            weights='uniform'),\n","             iid='deprecated', n_jobs=-1,\n","             param_grid={'metric': ('manhattan', 'euclidian'),\n","                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n","                         'weights': ('uniform', 'distance')},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring='accuracy', verbose=0)"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"SO7E6G8jKxZp"},"source":["Выведем лучшие параметры"]},{"cell_type":"code","metadata":{"id":"md48pHrMKxZq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633648608868,"user_tz":-180,"elapsed":217,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"188c4e1e-c6e2-4758-a6e2-bb7a594015a2"},"source":["params = clf_grid.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"M05n9l8pKxZt"},"source":["### Вопрос 2:\n","* Какую metric следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"Pmjx38OoKxZt"},"source":["### Вопрос 3:\n","* Сколько n_neighbors следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"eqLeJUP8KxZu"},"source":["### Вопрос 4:\n","* Какой тип weights следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"aBmiDbvV25qI"},"source":["Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."]},{"cell_type":"code","metadata":{"id":"ig_vS8O925qI"},"source":["optimal_clf = clf_grid.best_estimator_\n","# Обучение. Ваш код здесь\n","pred_prob = optimal_clf.predict(test_feature_matrix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kkapT38KxZz","colab":{"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"status":"ok","timestamp":1633649292513,"user_tz":-180,"elapsed":714,"user":{"displayName":"Дмитрий Вахромов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03846671125283843827"}},"outputId":"f88c5754-cc2d-4a81-df8b-8f07a84b06e7"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","\n","unique, freq = np.unique(test_labels, return_counts=True)\n","freq = list(map(lambda x: x / len(test_labels),freq))\n","\n","pred_freq = pred_prob.mean(axis=0)\n","plt.figure(figsize=(10, 8))\n","plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n","plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n","plt.ylim(0, 0.54)\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"gp4uDyLmKxZ3"},"source":["### Вопрос 5:\n","* Какая прогнозируемая вероятность pred_freq класса под номером 3 (до 2 знаков после запятой)?"]}]}